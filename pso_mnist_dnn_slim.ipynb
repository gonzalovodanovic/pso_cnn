{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de hiperparámetros de modelos de aprendizaje profundo utilizando Particle Swarm Optimization\n",
    "\n",
    "## Bibliotecas \n",
    "\n",
    "- NumPy\n",
    "- TensorFlow \n",
    "- Keras\n",
    "- Optunity\n",
    "\n",
    "Además, se agrega la configuración necesaria para que el experimento sea reproducible. Esta informacion  fue obtenida de la pagina oficial de Keras (https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development). Para que el resultado sea exactamente el mismo en todas las ejecuciones no es posible utilizar paralelismo, esto hace que el tiempo de ejecución aumente considerablemente. Sin embargo, la diferencia entre experimentos al utilizar paralelismo es baja (tercer digito) por lo que se decidió aceptar esta diferencia y reducir los tiempos de computo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1234)\n",
    "import random as rn\n",
    "rn.seed(12345)\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0' \n",
    "from keras import backend as K\n",
    "\n",
    "import math\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import optunity\n",
    "import optunity.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Input\n",
    "from keras.layers import Reshape, MaxPooling2D\n",
    "from keras.layers import Conv2D, Dense, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Funciones adicionales para graficar (blackbox)\n",
    "def plot_example_errors():\n",
    "    # Use TensorFlow to get a list of boolean values\n",
    "    # whether each test-image has been correctly classified,\n",
    "    # and a list for the predicted class of each image.\n",
    "    correct, cls_pred = session.run([correct_prediction, y_pred_cls],\n",
    "                                    feed_dict=feed_dict_test)\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = data.test.images[incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = data.test.cls[incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])\n",
    "\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "    fig.savefig('plot_images.pdf')\n",
    "\n",
    "def print_accuracy():   \n",
    "    # Use TensorFlow to compute the accuracy.\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "    \n",
    "    # Print the accuracy.\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(acc))\n",
    "    \n",
    "    \n",
    "def print_confusion_matrix():\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = data.test.cls\n",
    "    \n",
    "    # Get the predicted classifications for the test-set.\n",
    "    cls_pred = session.run(y_pred_cls, feed_dict=feed_dict_test)\n",
    "\n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred)\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix as an image.\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "    # Make various adjustments to the plot.\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "\n",
    "def plot_weights():\n",
    "    # Get the values for the weights from the TensorFlow variable.\n",
    "    w = session.run(weights)\n",
    "    \n",
    "    # Get the lowest and highest values for the weights.\n",
    "    # This is used to correct the colour intensity across\n",
    "    # the images so they can be compared with each other.\n",
    "    w_min = np.min(w)\n",
    "    w_max = np.max(w)\n",
    "\n",
    "    # Create figure with 3x4 sub-plots,\n",
    "    # where the last 2 sub-plots are unused.\n",
    "    fig, axes = plt.subplots(3, 4)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Only use the weights for the first 10 sub-plots.\n",
    "        if i<10:\n",
    "            # Get the weights for the i'th digit and reshape it.\n",
    "            # Note that w.shape == (img_size_flat, 10)\n",
    "            image = w[:, i].reshape(img_shape)\n",
    "\n",
    "            # Set the label for the sub-plot.\n",
    "            ax.set_xlabel(\"Weights: {0}\".format(i))\n",
    "\n",
    "            # Plot the image.\n",
    "            ax.imshow(image, vmin=w_min, vmax=w_max, cmap='seismic')\n",
    "\n",
    "        # Remove ticks from each sub-plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "    fig.savefig('plot_weights.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "Se utiliza el conjunto de datos MNIST, el cual contiene 70.000 imagenes de 28x28 pixeles y las etiquetas verdaderas correspondientes. Cada una de las imagenes contiene un número del 0 al 9 escritos a mano, la etiqueta es un vector de 10 elementos con un uno en la ubicación (índice) que se corresponde con el valor representado en la imagen y los demas elementos en cero (codificacion \"one-hot\").\n",
    "\n",
    "Este conjunto de datos se divide en tres subconjuntos:\n",
    "\n",
    "- Entrenamiento\n",
    "- Test\n",
    "- Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Test-set:\t\t10000\n",
      "- Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)\n",
    "data.test.cls = np.array([label.argmax() for label in data.test.labels])\n",
    "#data.test.cls = np.argmax(data.test.labels, axis=1)\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"inData\"></a> Dimnsiones de los datos \n",
    "Se declaran variables que serán utilizadas a lo largo del código y que definen las dimensiones de los datos. Además, se muestran algunas imágenes del set de datos que se esta utilizando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea78f1fa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_size = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "# This is used for plotting the images.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Tuple with height, width and depth used to reshape arrays.\n",
    "# This is used for reshaping in Keras.\n",
    "img_shape_full = (img_size, img_size, 1)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10\n",
    "\n",
    "# Number of images per batch\n",
    "batch_size = 128\n",
    "\n",
    "# Get the first images from the test-set.\n",
    "images = data.test.images[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = data.test.cls[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n",
    "\n",
    "El propósito de TensorFlow es crear grafos computacionales (_computational graph_) que pueden ser ejecutado mas eficientemente que si el cálculo fuera realizado directamente en _Python_. TensorFlow puede ser mas eficiente que NumPy porque conoce el grafo computacional completo, mientras que NumPy únicamente conoce de una operación matemática por vez.\n",
    "\n",
    "Además, TensorFlow puede calcular autmáticamente los gradientes necesarios para optimizar las variables de los grafos y mejorar la performance del modelo. Esto se debe a que los grafos son una combinación de expresiones matemáticas simples, por lo que el gradiente del grafo se obtiene mediante la _chain rule_ de las derivadas.\n",
    "\n",
    "Un grafo de TensorFlow consiste de las siguientes partes:\n",
    "\n",
    "- Variables _placeholder_: usadas para la entrada de datos al grafo.\n",
    "- Variables del modelo: son aquellas que se modifican durante la optimización del moderlo.\n",
    "- Modelo: es esencialmente una funcion matemática que calcula una salida a partir de los datos entrada (las variables _placeholder_ y las variables del modelo).\n",
    "- Funcion de costo: se utiliza para guiar la optimización de las variables.\n",
    "- Método de optimización: actualiza las variables del modelo.\n",
    "\n",
    "## Variables _Placeholder_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, img_size_flat])\n",
    "y_true = tf.placeholder(tf.float32, [None, num_classes])\n",
    "y_true_cls = tf.placeholder(tf.int64, [None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables a optimizar del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.zeros([img_size_flat, num_classes]))\n",
    "biases = tf.Variable(tf.zeros([num_classes]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.matmul(x, weights) + biases\n",
    "y_pred = tf.nn.softmax(logits)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de pérdida (_loss_) a optimizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                        labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización: Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.5).minimize(cost)\n",
    "\n",
    "# Function to control the number of iterations\n",
    "def optimize(num_iterations):\n",
    "    for i in range(num_iterations):\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = data.train.next_batch(batch_size)\n",
    "        \n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        # Note that the placeholder for y_true_cls is not set\n",
    "        # because it is not used during training.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sesión de TensorFlow \n",
    "\n",
    "\n",
    "Es importante notar que hasta ahora no se realizo ningun cálculo en TensorFlow, únicamente se crearon los objetos de TensorFlow. Para poder ejecutarlo, es necesario primero crear una sesión e inicializar las variables de pesos y sesgos en cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea la variable $feed\\_dict\\_test$ la cual es usada como entrada al grafo de _TensorFlow_, se deben utilizar los nombres correctos de los nodos _placeholder_ creados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_test = {x: data.test.images,\n",
    "                  y_true: data.test.labels,\n",
    "                  y_true_cls: data.test.cls}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presición en la clasificación antes de realizar optimizaciones\n",
    "\n",
    "La presición en el set de test es del 9.8%, esto se debe a que el modelo únicamente fue inicializado pero no optimizado. El 9.8% de las imágenes son el dígito cero, como el modelo se inició en cero, este es el único dígito que clasifica correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test-set: 9.8%\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAD5CAYAAACj3GcTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noEpTRCSAKk0RkQD/H2eeucmW8uENAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea85137668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_example_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presición en la clasificación luego de una iteración de optimización\n",
    "\n",
    "Luego de una única iteración, el modelo incrementa su presición del 9.8% al 43.5%. Esto significa que clasifica mal 6 imagenes de cada 10, como puede verse a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test-set: 41.7%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAD5CAYAAACj3GcTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0BQRiUGFpohIDCo0RURi+H8sreKYb08bVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea80e31908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimize(num_iterations=1)\n",
    "print_accuracy()\n",
    "plot_example_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD5CAYAAAAZf+9zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea80da5080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presición en la clasificación luego de 1000 iteraciones de optimización\n",
    "\n",
    "Luego de 1000 iteraciones, el modelo clasifica mal una de cada diez imágenes aproximadamente. Como se demuestra a continuación, alguna de las clasificaciones erroneas están justificadas, ya que, es muy difícil diferenciar incluso para las personas, mientras que otras son bastante obvias y deberían haber sido clasificadas correctamente. Sin embargo, este modelo simple no puede comportarse mucho mejor, es necesario un modelo más complejo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test-set: 89.4%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAD5CAYAAACj3GcTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea87bcc5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We have already performed 10 iterations.\n",
    "optimize(num_iterations=990)\n",
    "print_accuracy()\n",
    "plot_example_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo ahora fue entrenado con 1000 iteraciones de optimización, cada iteración usando 100 imagenes del set de entrenamiento. Debido a la gran variedad de imágenes, los pesos ahora se volvieron muy difícil de interprtar y podriamos preguntarnos si el modelo realmente entendió como los digitos se componen de lineas o si simplemente el modelo memorizó diferentes variaciones de pixeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD5CAYAAAAZf+9zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAiCkggFHARBUBKhgIMgCEriZ3dhDasjXz3mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea87acacf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se grafica la matriz de confusión que nos permite analizar en detalle las clasificaciones erroneas. Por ejemplo, nos muestra que las imágenes con el digito 5, a veces son confundidas con digitos como el 3, 8, o 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 947    0    1    2    0    5   15    2    4    4]\n",
      " [   0 1122    2    4    0    1    3    2    1    0]\n",
      " [   3   32  839   30    8    6   17    8   79   10]\n",
      " [   5    0   13  912    5   18    5    7   31   14]\n",
      " [   3    3    6    1  818    1   17    6   12  115]\n",
      " [  14    3    0   47   11  715   23    3   60   16]\n",
      " [   8    3    5    2    5    7  922    2    4    0]\n",
      " [   1   12   15   18    7    1    0  901    2   71]\n",
      " [  11   30    3   26    8   25    8    5  829   29]\n",
      " [   5    9    0   12   15    5    1   10   15  937]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEmCAYAAABcYEo9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea838e0f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se cierra la sesión de _TensorFlow_ y se liberan los recursos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network con Keras\n",
    "\n",
    "A continuación, se crea una función para crear la estructura de la red neuronal a partir de los hiperparámetros:\n",
    "- $num\\_dense\\_layers$: número de capas de la red.\n",
    "- $activation$: método de activación de las neuronas, puede ser ReLU o Sigmoid.\n",
    "- $learning\\_rate$:  _learning rate_ del optimizador Adam.\n",
    "- $num\\_dense\\_nodes$: número de neuronas en cada capa.\n",
    "\n",
    "La API _keras_ tiene dos modos de construcción de redes neuronales, el mas simple es el llamado _Sequential Model_ donde las capas se van agregando en forma secuencial. Como el número de capas es un hiperparámetro, se utiliza un bucle _for_ para agregar las capas secuencialmente.\n",
    "\n",
    "Una vez definida la arquitectura della red neuronal, es necesario agregar la función de pérdida, el optimizados y la métrica de medicion de _performance_. Esto se hace mediante la compilación del modelo. Como se estableció anteriormente, se elige como optimizador el algoritmo _Adam_, como funcón de pérdida $categorical\\_crossentropy$ y como métrica de _performance_ la presición de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the neural network with these hyper-parameters\n",
    "def create_model (num_dense_layers, activation,\n",
    "                 learning_rate, num_dense_nodes):\n",
    "    # Start construction of a Keras Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an input layer which is similar to a feed_dict in TensorFlow.\n",
    "    # Note that the input-shape must be a tuple containing the image-size.\n",
    "    model.add(InputLayer(input_shape=(img_size_flat,)))\n",
    "\n",
    "    # Add fully-connected / dense layers.\n",
    "    # The number of layers is a hyper-parameter we want to optimize.\n",
    "    for i in range(int(num_dense_layers)):\n",
    "        # Name of the layer. This is not really necessary\n",
    "        # because Keras should give them unique names.\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "\n",
    "        # Add the dense / fully-connected layer to the model.\n",
    "        # This has two hyper-parameters we want to optimize:\n",
    "        # The number of nodes and the activation function.\n",
    "        model.add(Dense(int(num_dense_nodes[i]),\n",
    "                        activation=activation,\n",
    "                        name=name))\n",
    "        if(activation == 'linear'):\n",
    "            model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "            \n",
    "    # Last fully-connected / dense layer with softmax-activation\n",
    "    # for use in classification.\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Use the Adam method for training the network.\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "    # In Keras we need to compile the model so it can be trained.\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de hiperparámetros\n",
    "\n",
    "### Espacio de búsqueda\n",
    " \n",
    " Los hiperparámetros a optimizar son:\n",
    " \n",
    "- $num\\_dense\\_layers$: número de capas de la red.\n",
    "- $activation$: método de activación de las neuronas, puede ser ReLU o Sigmoid.\n",
    "- $learning\\_rate$: _learning rate_ del optimizador Adam.\n",
    "- $num\\_dense\\_nodes$: número de neuronas en cada capa.\n",
    "\n",
    "A continuación se define el espacio de búsqueda definiendo los límites y una función que verifica que la partícula se encuentre dentro de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optunity PSO optimization search space\n",
    "# Activation \n",
    "activation_cat = ['relu', 'sigmoid', 'tanh', 'linear']\n",
    "# Maximum and minimum number of nodes or neurons\n",
    "max_dense_nodes = 128 \n",
    "min_dense_nodes = 10\n",
    "# Maximum and minimum learning rate for the optimizer\n",
    "max_learning_rate = 1e-2\n",
    "min_learning_rate = 1e-6\n",
    "\n",
    "search = {'DNN': {'1_layer': {'layer1_lr': [min_learning_rate, max_learning_rate],\n",
    "                              'layer1_nodes_l1': [min_dense_nodes, max_dense_nodes],\n",
    "                              'layer1_act': [0,3]},\n",
    "                  '2_layer': {'layer2_lr': [min_learning_rate, max_learning_rate],\n",
    "                              'layer2_nodes_l1': [min_dense_nodes, max_dense_nodes],\n",
    "                              'layer2_nodes_l2': [min_dense_nodes, max_dense_nodes],\n",
    "                              'layer2_act': [0,3]},\n",
    "                  '3_layer': {'layer3_lr': [min_learning_rate, max_learning_rate],\n",
    "                              'layer3_nodes_l1': [min_dense_nodes, max_dense_nodes],\n",
    "                              'layer3_nodes_l2': [min_dense_nodes, max_dense_nodes],\n",
    "                              'layer3_nodes_l3': [min_dense_nodes, max_dense_nodes],\n",
    "                              'layer3_act': [0,3]}\n",
    "                  }\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguientes funciones se utilizan para calcular el valor _fitness_ de cada partícula, en este caso, el _fitness_ es la presición con que se logró clasificar el set de validación. Evaluar la precisión con que se clasifica, implica crear el modelo con los hiperparámetros que la partícula establece, entrenar el modelo y luego evaluarlo.\n",
    "La creación del modelo se realiza llamando a la función $create\\_model$ descripta anteriormente. Una vez que el model fue definido completamente con función de pérdida y optimizador, es necesario entrenarlo. Esta función toma dos _numpy-arrays_ y realiza tantos entrenamientos como se especifiquen en el argumento $epochs$ y utilizando el tamaño de _batch_ especificado.\n",
    "\n",
    "Finalmente, es momento obtener la métrica de calidad de clasificación (_accuracy_), esto se hace mediante la evaluación del modelo entrenado. Para esto no se puede utilizar el conjunto de _test_, por que se obtendria un set de parámetros especificamente para este set de datos causando _overfitting_. Por esto se utiliza la técnica de _k-fold cross-validation_ donde el conjunto de entrenamiento se divide en $k$ pliegues, y luego se itera realizando $k$ entrenamientos y utilizando un pligue como validaciòn distinto en cada uno de ellos. Se obtenienen 5 resultados que luego se promedian para obtener el valor final de _fitness_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the fitness value\n",
    "def calculate_fitness (num_dense_layers, activation,\n",
    "                       learning_rate, num_dense_nodes):\n",
    "    # number of folds\n",
    "    k = 5 \n",
    "    # calculate the fold size\n",
    "    n_samples = len(data.train.images)\n",
    "    fold_size = n_samples // k\n",
    "    # Create list for saving the scores \n",
    "    scores = []\n",
    "    masks = []\n",
    "    for fold in range(k):\n",
    "        # Creation of the tensorFlow model with the PSO particle parameters\n",
    "        model = create_model(num_dense_layers, activation, learning_rate, num_dense_nodes)\n",
    "        if fold == 0:\n",
    "            print(activation)\n",
    "            print(model.summary())\n",
    "        # generate a boolean mask for the test set in this fold\n",
    "        test_mask = np.zeros(n_samples, dtype=bool)\n",
    "        test_mask[fold * fold_size : (fold + 1) * fold_size] = True\n",
    "        # store the mask for visualization\n",
    "        masks.append(test_mask)\n",
    "        # create training and test sets using this mask\n",
    "        X_test, y_test = data.train.images[test_mask], data.train.labels[test_mask]\n",
    "        X_train, y_train = data.train.images[~test_mask], data.train.labels[~test_mask]\n",
    "        # fit the classifier\n",
    "        ## Training\n",
    "        model.fit(x=X_train,\n",
    "                  y=y_train,\n",
    "                  epochs=3,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=0)\n",
    "        ## Evaluation\n",
    "        result = model.evaluate(x=X_test,\n",
    "                                y=y_test,\n",
    "                                verbose=0)\n",
    "        # compute the score and record it\n",
    "        scores.append(result[1])\n",
    "       \n",
    "        print(\"Fold: \" + str(fold))        \n",
    "        print(\"{0}: {1:.2%}\".format(model.metrics_names[1], result[1]),model.metrics_names[0],result[0])\n",
    "        # Delete the Keras model with these hyper-parameters from memory. \n",
    "        del model\n",
    "        # Clear the Keras session, otherwise it will keep adding new\n",
    "        # models to the same TensorFlow graph each time we create\n",
    "        # a model with a different set of hyper-parameters.\n",
    "        K.clear_session()\n",
    "        session.close()\n",
    "    print(np.abs(np.mean(scores)))\n",
    "    return (np.abs(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 capas ocultas = Clasificador Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0050005\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 91.77% loss 0.279128506704\n",
      "Fold: 1\n",
      "acc: 91.58% loss 0.295163570957\n",
      "Fold: 2\n",
      "acc: 92.16% loss 0.292704672207\n",
      "Fold: 3\n",
      "acc: 91.95% loss 0.290480927034\n",
      "Fold: 4\n",
      "acc: 91.25% loss 0.302580276262\n",
      "0.91741818181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91741818180951218"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_dense_layers = 0\n",
    "num_dense_nodes = [0,0,0,0,0]\n",
    "learning_rate=(min_learning_rate + max_learning_rate)/2\n",
    "print(learning_rate)\n",
    "calculate_fitness(num_dense_layers,activation_cat[0],learning_rate, num_dense_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Optunity\n",
    " \n",
    " Optunity es una biblioteca que contiene varios optimizadores de hiperparámetros, incluyendo __PSO__. En el siguiente código, se inicializa el _solver_ con los siguientes hiperparametros del _particle swarm_:\n",
    "\n",
    "- num_particles (int): Número de partículas\n",
    "- num_generations (int): Máximo número de generaciones\n",
    "- max_speed (float or None): Velocidad máxima de cada partícula\n",
    "- phi1 (float): Coeficiente de aceleración que determina la influencia relativa del _local best_\n",
    "- phi2 (float): Coeficiente de aceleración que determina la influencia relativa del _global best_\n",
    "- kwargs ({'name': [lb, ub], ..}): Dimensiones del espacio de busqueda y sus respectivos valores máximos y mínimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 capas ocultas = Clasificador Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 capa oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 33)                25905     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                340       \n",
      "=================================================================\n",
      "Total params: 26,245\n",
      "Trainable params: 26,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 94.89% loss 0.174245655911\n",
      "Fold: 1\n",
      "acc: 94.50% loss 0.184360369569\n",
      "Fold: 2\n",
      "acc: 95.15% loss 0.17826475791\n",
      "Fold: 3\n",
      "acc: 94.68% loss 0.18694214664\n",
      "Fold: 4\n",
      "acc: 94.54% loss 0.184599677709\n",
      "0.947527272719\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 97)                76145     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                980       \n",
      "=================================================================\n",
      "Total params: 77,125\n",
      "Trainable params: 77,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.41% loss 0.120377413574\n",
      "Fold: 1\n",
      "acc: 96.16% loss 0.127907207833\n",
      "Fold: 2\n",
      "acc: 96.39% loss 0.124734781011\n",
      "Fold: 3\n",
      "acc: 96.04% loss 0.128689388396\n",
      "Fold: 4\n",
      "acc: 95.85% loss 0.131608662418\n",
      "0.961690909074\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 17)                13345     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                180       \n",
      "=================================================================\n",
      "Total params: 13,525\n",
      "Trainable params: 13,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 89.85% loss 0.438261891387\n",
      "Fold: 1\n",
      "acc: 89.45% loss 0.434474558028\n",
      "Fold: 2\n",
      "acc: 90.43% loss 0.417271982648\n",
      "Fold: 3\n",
      "acc: 89.86% loss 0.441791290457\n",
      "Fold: 4\n",
      "acc: 89.13% loss 0.447843436328\n",
      "0.897436363645\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 81)                63585     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                820       \n",
      "=================================================================\n",
      "Total params: 64,405\n",
      "Trainable params: 64,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.65% loss 0.117634716169\n",
      "Fold: 1\n",
      "acc: 96.08% loss 0.128795089696\n",
      "Fold: 2\n",
      "acc: 96.56% loss 0.117851782173\n",
      "Fold: 3\n",
      "acc: 95.83% loss 0.135534482785\n",
      "Fold: 4\n",
      "acc: 96.18% loss 0.127245020307\n",
      "0.962618181801\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 112)               87920     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1130      \n",
      "=================================================================\n",
      "Total params: 89,050\n",
      "Trainable params: 89,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.63% loss 0.107873246588\n",
      "Fold: 1\n",
      "acc: 96.05% loss 0.127057324166\n",
      "Fold: 2\n",
      "acc: 96.91% loss 0.10774794377\n",
      "Fold: 3\n",
      "acc: 95.97% loss 0.130584412392\n",
      "Fold: 4\n",
      "acc: 96.60% loss 0.111604977001\n",
      "0.964327272736\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 125)               98125     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1260      \n",
      "=================================================================\n",
      "Total params: 99,385\n",
      "Trainable params: 99,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.65% loss 0.145717146966\n",
      "Fold: 1\n",
      "acc: 95.62% loss 0.149676969921\n",
      "Fold: 2\n",
      "acc: 95.44% loss 0.156329904933\n",
      "Fold: 3\n",
      "acc: 95.62% loss 0.14723179368\n",
      "Fold: 4\n",
      "acc: 95.28% loss 0.155931925725\n",
      "0.955199999957\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 166)               130310    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 166)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1670      \n",
      "=================================================================\n",
      "Total params: 131,980\n",
      "Trainable params: 131,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 94.22% loss 0.207625997977\n",
      "Fold: 1\n",
      "acc: 93.33% loss 0.23168309759\n",
      "Fold: 2\n",
      "acc: 93.92% loss 0.227034936791\n",
      "Fold: 3\n",
      "acc: 93.68% loss 0.223649408481\n",
      "Fold: 4\n",
      "acc: 93.06% loss 0.239285347505\n",
      "0.936418181818\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 80)                62800     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 63,610\n",
      "Trainable params: 63,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.75% loss 0.110095273243\n",
      "Fold: 1\n",
      "acc: 96.21% loss 0.11937150649\n",
      "Fold: 2\n",
      "acc: 96.00% loss 0.147270118745\n",
      "Fold: 3\n",
      "acc: 96.25% loss 0.134137388523\n",
      "Fold: 4\n",
      "acc: 96.43% loss 0.119609127304\n",
      "0.963272727255\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 41)                32185     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                420       \n",
      "=================================================================\n",
      "Total params: 32,605\n",
      "Trainable params: 32,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.22% loss 0.158892961777\n",
      "Fold: 1\n",
      "acc: 95.39% loss 0.158929545034\n",
      "Fold: 2\n",
      "acc: 96.01% loss 0.142227354862\n",
      "Fold: 3\n",
      "acc: 95.84% loss 0.141434275657\n",
      "Fold: 4\n",
      "acc: 95.66% loss 0.146366185433\n",
      "0.956236363619\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 71)                55735     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 71)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                720       \n",
      "=================================================================\n",
      "Total params: 56,455\n",
      "Trainable params: 56,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.75% loss 0.106091354012\n",
      "Fold: 1\n",
      "acc: 96.05% loss 0.130774801955\n",
      "Fold: 2\n",
      "acc: 96.28% loss 0.126976585884\n",
      "Fold: 3\n",
      "acc: 96.31% loss 0.120913146419\n",
      "Fold: 4\n",
      "acc: 96.67% loss 0.111890681709\n",
      "0.96412727271\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 202)               158570    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 202)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2030      \n",
      "=================================================================\n",
      "Total params: 160,600\n",
      "Trainable params: 160,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.75% loss 0.101623840859\n",
      "Fold: 1\n",
      "acc: 96.86% loss 0.106925030157\n",
      "Fold: 2\n",
      "acc: 97.23% loss 0.0969325672883\n",
      "Fold: 3\n",
      "acc: 97.00% loss 0.0983322753683\n",
      "Fold: 4\n",
      "acc: 96.47% loss 0.114611062582\n",
      "0.968636363645\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 218)               171130    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 218)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2190      \n",
      "=================================================================\n",
      "Total params: 173,320\n",
      "Trainable params: 173,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 11.18% loss 14.3157991194\n",
      "Fold: 1\n",
      "acc: 9.83% loss 14.5341260154\n",
      "Fold: 2\n",
      "acc: 10.10% loss 14.4901675491\n",
      "Fold: 3\n",
      "acc: 9.54% loss 14.5810150015\n",
      "Fold: 4\n",
      "acc: 0.06% loss 16.1046313948\n",
      "0.081418181816\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 146)               114610    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1470      \n",
      "=================================================================\n",
      "Total params: 116,080\n",
      "Trainable params: 116,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.49% loss 0.155527263239\n",
      "Fold: 1\n",
      "acc: 95.11% loss 0.159777767928\n",
      "Fold: 2\n",
      "acc: 95.08% loss 0.172570511445\n",
      "Fold: 3\n",
      "acc: 95.10% loss 0.168177134274\n",
      "Fold: 4\n",
      "acc: 95.35% loss 0.156984826007\n",
      "0.952254545437\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 46)                36110     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 46)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                470       \n",
      "=================================================================\n",
      "Total params: 36,580\n",
      "Trainable params: 36,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.14% loss 0.129139203727\n",
      "Fold: 1\n",
      "acc: 95.89% loss 0.139436144962\n",
      "Fold: 2\n",
      "acc: 96.00% loss 0.146021726797\n",
      "Fold: 3\n",
      "acc: 96.07% loss 0.129184403883\n",
      "Fold: 4\n",
      "acc: 95.57% loss 0.14789694057\n",
      "0.959345454545\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 52)                40820     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 52)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                530       \n",
      "=================================================================\n",
      "Total params: 41,350\n",
      "Trainable params: 41,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.27% loss 0.122401758645\n",
      "Fold: 1\n",
      "acc: 95.64% loss 0.138947963216\n",
      "Fold: 2\n",
      "acc: 96.26% loss 0.137977747281\n",
      "Fold: 3\n",
      "acc: 96.38% loss 0.124530220055\n",
      "Fold: 4\n",
      "acc: 95.37% loss 0.148078420032\n",
      "0.959854545429\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 279)               219015    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2800      \n",
      "=================================================================\n",
      "Total params: 221,815\n",
      "Trainable params: 221,815\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.98% loss 0.102751493516\n",
      "Fold: 1\n",
      "acc: 96.63% loss 0.111716861909\n",
      "Fold: 2\n",
      "acc: 96.56% loss 0.114763016511\n",
      "Fold: 3\n",
      "acc: 96.72% loss 0.107995887139\n",
      "Fold: 4\n",
      "acc: 96.67% loss 0.108395694704\n",
      "0.967127272727\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 264)               207240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2650      \n",
      "=================================================================\n",
      "Total params: 209,890\n",
      "Trainable params: 209,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 11.18% loss 14.3157991194\n",
      "Fold: 1\n",
      "acc: 10.75% loss 14.3861326453\n",
      "Fold: 2\n",
      "acc: 9.95% loss 14.5150773454\n",
      "Fold: 3\n",
      "acc: 9.57% loss 14.5751538967\n",
      "Fold: 4\n",
      "acc: 9.33% loss 14.6147164619\n",
      "0.101545454548\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 214)               167990    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2150      \n",
      "=================================================================\n",
      "Total params: 170,140\n",
      "Trainable params: 170,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.95% loss 0.134249367121\n",
      "Fold: 1\n",
      "acc: 96.53% loss 0.120036298392\n",
      "Fold: 2\n",
      "acc: 96.05% loss 0.128081652178\n",
      "Fold: 3\n",
      "acc: 95.37% loss 0.154368219652\n",
      "Fold: 4\n",
      "acc: 96.20% loss 0.120226793911\n",
      "0.960199999991\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 129)               101265    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1300      \n",
      "=================================================================\n",
      "Total params: 102,565\n",
      "Trainable params: 102,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.96% loss 0.137629311388\n",
      "Fold: 1\n",
      "acc: 95.53% loss 0.147490067043\n",
      "Fold: 2\n",
      "acc: 95.78% loss 0.142604934121\n",
      "Fold: 3\n",
      "acc: 95.92% loss 0.141707424065\n",
      "Fold: 4\n",
      "acc: 95.62% loss 0.146336833862\n",
      "0.957618181801\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 143)               112255    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 143)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1440      \n",
      "=================================================================\n",
      "Total params: 113,695\n",
      "Trainable params: 113,695\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.95% loss 0.102128841344\n",
      "Fold: 1\n",
      "acc: 97.14% loss 0.0965382799499\n",
      "Fold: 2\n",
      "acc: 97.35% loss 0.0961026724066\n",
      "Fold: 3\n",
      "acc: 96.17% loss 0.125360508877\n",
      "Fold: 4\n",
      "acc: 96.71% loss 0.108155735739\n",
      "0.968654545446\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 267)               209595    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2680      \n",
      "=================================================================\n",
      "Total params: 212,275\n",
      "Trainable params: 212,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.88% loss 0.103613788777\n",
      "Fold: 1\n",
      "acc: 96.18% loss 0.12924726513\n",
      "Fold: 2\n",
      "acc: 96.68% loss 0.117256829132\n",
      "Fold: 3\n",
      "acc: 96.47% loss 0.124257288039\n",
      "Fold: 4\n",
      "acc: 96.53% loss 0.107253049063\n",
      "0.965490909074\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 298)               233930    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2990      \n",
      "=================================================================\n",
      "Total params: 236,920\n",
      "Trainable params: 236,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 94.73% loss 0.18301378773\n",
      "Fold: 1\n",
      "acc: 94.42% loss 0.182551911132\n",
      "Fold: 2\n",
      "acc: 95.15% loss 0.176597681652\n",
      "Fold: 3\n",
      "acc: 94.67% loss 0.180314602776\n",
      "Fold: 4\n",
      "acc: 94.17% loss 0.18905640704\n",
      "0.946272727255\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 264)               207240    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2650      \n",
      "=================================================================\n",
      "Total params: 209,890\n",
      "Trainable params: 209,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.45% loss 0.152170720538\n",
      "Fold: 1\n",
      "acc: 95.56% loss 0.144603859505\n",
      "Fold: 2\n",
      "acc: 94.84% loss 0.17288065477\n",
      "Fold: 3\n",
      "acc: 95.80% loss 0.137621269357\n",
      "Fold: 4\n",
      "acc: 95.76% loss 0.135267843043\n",
      "0.95483636361\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 217)               170345    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 217)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2180      \n",
      "=================================================================\n",
      "Total params: 172,525\n",
      "Trainable params: 172,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 10.17% loss 14.4783078676\n",
      "Fold: 1\n",
      "acc: 9.94% loss 14.5164584829\n",
      "Fold: 2\n",
      "acc: 10.10% loss 14.4901675491\n",
      "Fold: 3\n",
      "acc: 8.84% loss 14.6937405583\n",
      "Fold: 4\n",
      "acc: 11.52% loss 14.2610180775\n",
      "0.101127272728\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 235)               184475    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2360      \n",
      "=================================================================\n",
      "Total params: 186,835\n",
      "Trainable params: 186,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 97.08% loss 0.097562806013\n",
      "Fold: 1\n",
      "acc: 96.87% loss 0.107049274493\n",
      "Fold: 2\n",
      "acc: 97.01% loss 0.104425786807\n",
      "Fold: 3\n",
      "acc: 96.67% loss 0.109837162058\n",
      "Fold: 4\n",
      "acc: 96.64% loss 0.106575205114\n",
      "0.968545454545\n",
      "{'activation': 3.0796019661630685, 'learning_rate': 0.004817115709036599, 'dense_layer0': 143.7588831689041}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "f = create_objective_function()\n",
    "omega = 1.0/(2.0*np.log(2))\n",
    "phi = 0.5 + np.log(2)\n",
    "\n",
    "num_dense_layers = 1\n",
    "\n",
    "def create_objective_function():\n",
    "    def f(activation,\n",
    "          learning_rate, \n",
    "          dense_layer0):\n",
    "\n",
    "        num_dense_nodes = [dense_layer0,0,0,0,0]\n",
    "        if (activation > 3):\n",
    "            activation = 3\n",
    "        fitness = 1.0/calculate_fitness(num_dense_layers,activation_cat[round(activation)],learning_rate, num_dense_nodes)\n",
    "        return fitness\n",
    "    return f\n",
    "\n",
    "pso = optunity.solvers.ParticleSwarm(num_particles=5,\n",
    "                                     num_generations=5,\n",
    "                                     max_speed=omega, \n",
    "                                     phi1=phi,phi2=phi,\n",
    "                                     activation=[0, 3], \n",
    "                                     learning_rate=[min_learning_rate, max_learning_rate], \n",
    "                                     dense_layer0=[1, max_dense_nodes])\n",
    "pars,details = pso.minimize(f)\n",
    "print(pars)\n",
    "num_dense_nodes_res = [int(pars['dense_layer0']),0,0,0,0]\n",
    "\n",
    "end_time = time.time()\n",
    "time_dif = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 781.0128231048584\n",
      "Activation function: linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 143)               112255    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 143)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1440      \n",
      "=================================================================\n",
      "Total params: 113,695\n",
      "Trainable params: 113,695\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "acc: 97.31% loss 0.0855314503635\n"
     ]
    }
   ],
   "source": [
    "print(\"Time: \" + str(time_dif))\n",
    "\n",
    "model = create_model(num_dense_layers, \n",
    "                     activation_cat[round(pars['activation'])], \n",
    "                     pars['learning_rate'], \n",
    "                     num_dense_nodes_res)\n",
    "\n",
    "print(\"Activation function: \" + str(activation_cat[round(pars['activation'])]))\n",
    "print(model.summary())\n",
    "model.fit(x=data.train.images,\n",
    "          y=data.train.labels,\n",
    "          epochs=3,\n",
    "          batch_size=batch_size,\n",
    "          verbose=0)\n",
    "## Evaluation\n",
    "result = model.evaluate(x=data.test.images,\n",
    "                        y=data.test.labels,\n",
    "                        verbose=0)\n",
    "\n",
    "print(\"{0}: {1:.2%}\".format(model.metrics_names[1], result[1]),model.metrics_names[0],result[0])\n",
    "# Delete the Keras model with these hyper-parameters from memory. \n",
    "del model\n",
    "# Clear the Keras session, otherwise it will keep adding new\n",
    "# models to the same TensorFlow graph each time we create\n",
    "# a model with a different set of hyper-parameters.\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 capas Ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.83544921875 0.0007870541992187501 18.05322265625 98.91650390625\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 18)                14130     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 98)                1862      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                990       \n",
      "=================================================================\n",
      "Total params: 16,982\n",
      "Trainable params: 16,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 93.68% loss 0.213752129425\n",
      "Fold: 1\n",
      "acc: 93.46% loss 0.216321068341\n",
      "Fold: 2\n",
      "acc: 93.65% loss 0.220552415328\n",
      "Fold: 3\n",
      "acc: 93.42% loss 0.224116514461\n",
      "Fold: 4\n",
      "acc: 93.09% loss 0.226874544854\n",
      "0.934618181827\n",
      "0.33544921875 0.005786554199218751 81.55322265625 35.41650390625\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 81)                63585     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 35)                2870      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                360       \n",
      "=================================================================\n",
      "Total params: 66,815\n",
      "Trainable params: 66,815\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.65% loss 0.111557458764\n",
      "Fold: 1\n",
      "acc: 96.01% loss 0.131716319719\n",
      "Fold: 2\n",
      "acc: 96.58% loss 0.115810792821\n",
      "Fold: 3\n",
      "acc: 96.48% loss 0.123868248283\n",
      "Fold: 4\n",
      "acc: 96.02% loss 0.132607144403\n",
      "0.963472727238\n",
      "0.24169921875 0.00109952294921875 101.39697265625 63.19775390625\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 101)               79285     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 63)                6426      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                640       \n",
      "=================================================================\n",
      "Total params: 86,351\n",
      "Trainable params: 86,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.43% loss 0.120841135629\n",
      "Fold: 1\n",
      "acc: 96.21% loss 0.126790013624\n",
      "Fold: 2\n",
      "acc: 96.21% loss 0.126715032827\n",
      "Fold: 3\n",
      "acc: 96.30% loss 0.122367733758\n",
      "Fold: 4\n",
      "acc: 96.42% loss 0.117762769984\n",
      "0.963127272701\n",
      "1.74169921875 0.00609902294921875 37.89697265625 126.69775390625\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 37)                29045     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 126)               4788      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1270      \n",
      "=================================================================\n",
      "Total params: 35,103\n",
      "Trainable params: 35,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.50% loss 0.147527008364\n",
      "Fold: 1\n",
      "acc: 95.46% loss 0.150385498795\n",
      "Fold: 2\n",
      "acc: 95.65% loss 0.144932864896\n",
      "Fold: 3\n",
      "acc: 95.55% loss 0.150744736252\n",
      "Fold: 4\n",
      "acc: 95.21% loss 0.155218002518\n",
      "0.954763636338\n",
      "2.49169921875 0.0035992729492187506 6.14697265625 31.44775390625\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 31)                341       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                320       \n",
      "=================================================================\n",
      "Total params: 8,511\n",
      "Trainable params: 8,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 92.84% loss 0.245803111315\n",
      "Fold: 1\n",
      "acc: 91.67% loss 0.278128628438\n",
      "Fold: 2\n",
      "acc: 92.92% loss 0.24495864497\n",
      "Fold: 3\n",
      "acc: 92.53% loss 0.260250197584\n",
      "Fold: 4\n",
      "acc: 91.98% loss 0.266797699993\n",
      "0.923872727273\n",
      "2.2045539801360725 0.00292613131467674 -19.0383914972212 112.02405288599435\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 112)               1232      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1130      \n",
      "=================================================================\n",
      "Total params: 10,212\n",
      "Trainable params: 10,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 92.61% loss 0.23431061684\n",
      "Fold: 1\n",
      "acc: 92.85% loss 0.244355431974\n",
      "Fold: 2\n",
      "acc: 93.19% loss 0.248615876946\n",
      "Fold: 3\n",
      "acc: 92.49% loss 0.264664698227\n",
      "Fold: 4\n",
      "acc: 92.70% loss 0.254686640599\n",
      "0.927672727273\n",
      "2.0257227581012827 -0.0012248223338782744 88.34612468400529 30.229244237880707\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 88)                69080     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 30)                2670      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 72,060\n",
      "Trainable params: 72,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 15.19% loss 2.2951521036\n",
      "Fold: 1\n",
      "acc: 14.80% loss 2.21549604225\n",
      "Fold: 2\n",
      "acc: 12.33% loss 2.27994497871\n",
      "Fold: 3\n",
      "acc: 19.75% loss 2.15694133949\n",
      "Fold: 4\n",
      "acc: 23.06% loss 2.14689124766\n",
      "0.170272727272\n",
      "2.1060714132083502 0.004574732136121225 56.46268955778989 72.76731612093734\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 56)                43960     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 72)                4104      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                730       \n",
      "=================================================================\n",
      "Total params: 48,794\n",
      "Trainable params: 48,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.11% loss 0.132193475584\n",
      "Fold: 1\n",
      "acc: 95.55% loss 0.150406947303\n",
      "Fold: 2\n",
      "acc: 96.25% loss 0.123948325394\n",
      "Fold: 3\n",
      "acc: 95.99% loss 0.139169190673\n",
      "Fold: 4\n",
      "acc: 95.85% loss 0.138379840259\n",
      "0.959472727281\n",
      "3.495948223513377 0.012844527348876023 20.692734987931342 164.07977598953946\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 164)               3444      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 164)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1650      \n",
      "=================================================================\n",
      "Total params: 20,794\n",
      "Trainable params: 20,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 94.43% loss 0.183979434749\n",
      "Fold: 1\n",
      "acc: 95.56% loss 0.158896394009\n",
      "Fold: 2\n",
      "acc: 94.77% loss 0.18345283441\n",
      "Fold: 3\n",
      "acc: 94.21% loss 0.200941650827\n",
      "Fold: 4\n",
      "acc: 94.20% loss 0.19372231702\n",
      "0.946345454537\n",
      "0.32765665741655514 0.0005280135234728427 -10.289830337935754 14.883247753156365\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 14)                154       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                150       \n",
      "=================================================================\n",
      "Total params: 8,154\n",
      "Trainable params: 8,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 89.45% loss 0.364960693262\n",
      "Fold: 1\n",
      "acc: 89.42% loss 0.355304103201\n",
      "Fold: 2\n",
      "acc: 89.53% loss 0.385344629743\n",
      "Fold: 3\n",
      "acc: 90.24% loss 0.359564765811\n",
      "Fold: 4\n",
      "acc: 88.76% loss 0.38322625041\n",
      "0.894781818199\n",
      "2.1167094955664774 0.007288208369160564 53.15317751183386 96.54249353723827\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 53)                41605     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 96)                5184      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                970       \n",
      "=================================================================\n",
      "Total params: 47,759\n",
      "Trainable params: 47,759\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.75% loss 0.140608246687\n",
      "Fold: 1\n",
      "acc: 95.28% loss 0.16056167269\n",
      "Fold: 2\n",
      "acc: 95.55% loss 0.148283141488\n",
      "Fold: 3\n",
      "acc: 95.61% loss 0.149337867013\n",
      "Fold: 4\n",
      "acc: 95.76% loss 0.137208472293\n",
      "0.955909090918\n",
      "3.420545783938757 -0.007656223278971755 89.45314268269902 26.74147214798361\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 89)                69865     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 89)                0         \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 26)                2340      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                270       \n",
      "=================================================================\n",
      "Total params: 72,475\n",
      "Trainable params: 72,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 18.80% loss 2.24707564406\n",
      "Fold: 1\n",
      "acc: 12.75% loss 2.27164835098\n",
      "Fold: 2\n",
      "acc: 13.41% loss 2.2822315523\n",
      "Fold: 3\n",
      "acc: 12.63% loss 2.28164400742\n",
      "Fold: 4\n",
      "acc: 17.97% loss 2.28426573684\n",
      "0.151127272725\n",
      "3.286337930297947 0.008804954838964815 30.771980187123813 73.1994811016049\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 73)                2263      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 73)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                740       \n",
      "=================================================================\n",
      "Total params: 26,553\n",
      "Trainable params: 26,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 94.59% loss 0.177000136436\n",
      "Fold: 1\n",
      "acc: 95.07% loss 0.164065058714\n",
      "Fold: 2\n",
      "acc: 95.59% loss 0.152953941764\n",
      "Fold: 3\n",
      "acc: 94.75% loss 0.175997162444\n",
      "Fold: 4\n",
      "acc: 94.35% loss 0.203722148302\n",
      "0.948690909074\n",
      "1.5241096227082005 0.018621872431843357 27.953605998031435 138.5577722892001\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 27)                21195     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 138)               3864      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1390      \n",
      "=================================================================\n",
      "Total params: 26,449\n",
      "Trainable params: 26,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.05% loss 0.172849065182\n",
      "Fold: 1\n",
      "acc: 94.60% loss 0.175019886281\n",
      "Fold: 2\n",
      "acc: 94.14% loss 0.203362237001\n",
      "Fold: 3\n",
      "acc: 94.77% loss 0.192029758587\n",
      "Fold: 4\n",
      "acc: 93.35% loss 0.220775101034\n",
      "0.943818181827\n",
      "-1.8354657236985537 0.00020867664559668514 12.947700000732652 0.9111834502746881\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 12)                9420      \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 9,660\n",
      "Trainable params: 9,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 85.92% loss 0.512504885305\n",
      "Fold: 1\n",
      "acc: 82.99% loss 0.629250962908\n",
      "Fold: 2\n",
      "acc: 83.85% loss 0.592408602671\n",
      "Fold: 3\n",
      "acc: 83.11% loss 0.638930127231\n",
      "Fold: 4\n",
      "acc: 84.80% loss 0.550059710416\n",
      "0.841327272719\n",
      "1.0060264953484195 0.009992741830666434 144.76431260828303 50.71709498982705\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 144)               113040    \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 50)                7250      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 120,800\n",
      "Trainable params: 120,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.62% loss 0.106161703612\n",
      "Fold: 1\n",
      "acc: 96.55% loss 0.114952042112\n",
      "Fold: 2\n",
      "acc: 96.88% loss 0.104000422747\n",
      "Fold: 3\n",
      "acc: 96.16% loss 0.12043199651\n",
      "Fold: 4\n",
      "acc: 96.53% loss 0.114016745782\n",
      "0.965472727255\n",
      "4.492027569523206 -0.008202959795000797 87.25058159691038 32.64435426313751\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 87)                68295     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 87)                0         \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 32)                2816      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 71,441\n",
      "Trainable params: 71,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 10.73% loss 2.27015991194\n",
      "Fold: 1\n",
      "acc: 13.08% loss 2.26077839002\n",
      "Fold: 2\n",
      "acc: 9.62% loss 2.32771828443\n",
      "Fold: 3\n",
      "acc: 11.54% loss 2.27086674846\n",
      "Fold: 4\n",
      "acc: 17.11% loss 2.24610927911\n",
      "0.124145454546\n",
      "3.83785078180464 0.012173157525072283 27.148126855974844 50.8432477168389\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 27)                21195     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 50)                1400      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 23,105\n",
      "Trainable params: 23,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.21% loss 0.156275098191\n",
      "Fold: 1\n",
      "acc: 95.35% loss 0.156219248941\n",
      "Fold: 2\n",
      "acc: 95.39% loss 0.163975027446\n",
      "Fold: 3\n",
      "acc: 94.88% loss 0.182180226532\n",
      "Fold: 4\n",
      "acc: 94.40% loss 0.198278591462\n",
      "0.950472727255\n",
      "-0.6399329386252444 0.018292259801714898 55.73729461535406 46.94663719275093\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 55)                43175     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 46)                2576      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                470       \n",
      "=================================================================\n",
      "Total params: 46,221\n",
      "Trainable params: 46,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.72% loss 0.145569892272\n",
      "Fold: 1\n",
      "acc: 96.17% loss 0.138489901241\n",
      "Fold: 2\n",
      "acc: 96.01% loss 0.138404204161\n",
      "Fold: 3\n",
      "acc: 95.73% loss 0.151488786819\n",
      "Fold: 4\n",
      "acc: 95.27% loss 0.155693144457\n",
      "0.9578\n",
      "-3.190437289986243 0.001022286969096843 86.04325671942524 -0.361032016336722\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 86)                67510     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 10)                870       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 68,490\n",
      "Trainable params: 68,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.45% loss 0.158687812846\n",
      "Fold: 1\n",
      "acc: 95.13% loss 0.16754962479\n",
      "Fold: 2\n",
      "acc: 95.25% loss 0.169503899531\n",
      "Fold: 3\n",
      "acc: 95.04% loss 0.167241600354\n",
      "Fold: 4\n",
      "acc: 95.25% loss 0.16487604384\n",
      "0.95221818181\n",
      "-0.1046565048696384 0.012697275292172305 236.3754477047322 4.891696442415821\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 236)               185260    \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 10)                2370      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 187,740\n",
      "Trainable params: 187,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.03% loss 0.132441017396\n",
      "Fold: 1\n",
      "acc: 96.45% loss 0.13417452765\n",
      "Fold: 2\n",
      "acc: 95.68% loss 0.154263548767\n",
      "Fold: 3\n",
      "acc: 95.96% loss 0.164135002991\n",
      "Fold: 4\n",
      "acc: 96.21% loss 0.141013589885\n",
      "0.960672727247\n",
      "2.327985008189761 -0.0019735064628019676 99.88350421075587 42.705042108498134\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 99)                77715     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 42)                4200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                430       \n",
      "=================================================================\n",
      "Total params: 82,345\n",
      "Trainable params: 82,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 17.25% loss 2.22751133988\n",
      "Fold: 1\n",
      "acc: 22.15% loss 2.18917873608\n",
      "Fold: 2\n",
      "acc: 23.88% loss 2.172549001\n",
      "Fold: 3\n",
      "acc: 17.48% loss 2.26660352135\n",
      "Fold: 4\n",
      "acc: 13.52% loss 2.2767215023\n",
      "0.188581818174\n",
      "3.1137890251671507 0.015167551052907395 118.75926195242403 28.48580893320937\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 118)               92630     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 118)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 28)                3332      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                290       \n",
      "=================================================================\n",
      "Total params: 96,252\n",
      "Trainable params: 96,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.11% loss 0.130571568815\n",
      "Fold: 1\n",
      "acc: 96.45% loss 0.132757901992\n",
      "Fold: 2\n",
      "acc: 95.23% loss 0.167287924765\n",
      "Fold: 3\n",
      "acc: 95.47% loss 0.151078835262\n",
      "Fold: 4\n",
      "acc: 95.93% loss 0.14061677176\n",
      "0.958363636346\n",
      "-1.7400204182801575 0.014644550842596613 98.34458412359905 -44.64447166191307\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 98)                76930     \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 10)                990       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 78,030\n",
      "Trainable params: 78,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.45% loss 0.122655735411\n",
      "Fold: 1\n",
      "acc: 95.93% loss 0.141887454225\n",
      "Fold: 2\n",
      "acc: 96.16% loss 0.13815180396\n",
      "Fold: 3\n",
      "acc: 96.10% loss 0.141056779567\n",
      "Fold: 4\n",
      "acc: 95.77% loss 0.141777401176\n",
      "0.96081818181\n",
      "-1.0852538021280203 0.00586642882424031 177.65439181587442 44.63361449953385\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 177)               138945    \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 44)                7832      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                450       \n",
      "=================================================================\n",
      "Total params: 147,227\n",
      "Trainable params: 147,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 96.89% loss 0.110872759024\n",
      "Fold: 1\n",
      "acc: 96.76% loss 0.108943408783\n",
      "Fold: 2\n",
      "acc: 96.70% loss 0.132368496343\n",
      "Fold: 3\n",
      "acc: 97.12% loss 0.103086491239\n",
      "Fold: 4\n",
      "acc: 96.64% loss 0.12471803407\n",
      "0.96821818181\n",
      "{'activation': -1.0852538021280203, 'learning_rate': 0.00586642882424031, 'dense_layer0': 177.65439181587442, 'dense_layer1': 44.63361449953385}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "f = create_objective_function()\n",
    "omega = 1.0/(2.0*np.log(2))\n",
    "phi = 0.5 + np.log(2)\n",
    "\n",
    "num_dense_layers = 2\n",
    "\n",
    "def create_objective_function():\n",
    "    def f(activation,\n",
    "          learning_rate, \n",
    "          dense_layer0,\n",
    "          dense_layer1):\n",
    "\n",
    "        print(activation, learning_rate, dense_layer0,dense_layer1)\n",
    "        \n",
    "        if (activation > 3):\n",
    "            activation = 3\n",
    "        if (activation < 0):\n",
    "            activation = 0\n",
    "        if (learning_rate < min_learning_rate):\n",
    "            learning_rate = min_learning_rate\n",
    "        if (learning_rate > max_learning_rate):\n",
    "            learning_rate = max_learning_rate\n",
    "        if (dense_layer0 < min_dense_nodes):\n",
    "            dense_layer0 = min_dense_nodes\n",
    "        if (dense_layer1 < min_dense_nodes):\n",
    "            dense_layer1 = min_dense_nodes\n",
    "\n",
    "        num_dense_nodes = [dense_layer0,dense_layer1,0,0,0]            \n",
    "            \n",
    "        fitness = 1.0/calculate_fitness(num_dense_layers,activation_cat[round(activation)],learning_rate, num_dense_nodes)\n",
    "        return fitness\n",
    "    return f\n",
    "\n",
    "pso = optunity.solvers.ParticleSwarm(num_particles=5,\n",
    "                                     num_generations=5,\n",
    "                                     max_speed=omega, \n",
    "                                     phi1=phi,phi2=phi,\n",
    "                                     activation=[0, 3], \n",
    "                                     learning_rate=[min_learning_rate, max_learning_rate], \n",
    "                                     dense_layer0=[1, max_dense_nodes],\n",
    "                                     dense_layer1=[1, max_dense_nodes])\n",
    "pars,details = pso.minimize(f)\n",
    "print(pars)\n",
    "num_dense_nodes_res = [int(pars['dense_layer0']),int(pars['dense_layer1']),0,0,0]\n",
    "\n",
    "end_time = time.time()\n",
    "time_dif = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 687.4098429679871\n",
      "Activation function: linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 177)               138945    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 177)               0         \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 44)                7832      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                450       \n",
      "=================================================================\n",
      "Total params: 147,227\n",
      "Trainable params: 147,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "acc: 97.05% loss 0.106421305926\n"
     ]
    }
   ],
   "source": [
    "print(\"Time: \" + str(time_dif))\n",
    "\n",
    "model = create_model(num_dense_layers, \n",
    "                     activation_cat[round(pars['activation'])], \n",
    "                     pars['learning_rate'], \n",
    "                     num_dense_nodes_res)\n",
    "\n",
    "print(\"Activation function: \" + str(activation_cat[round(pars['activation'])]))\n",
    "print(model.summary())\n",
    "model.fit(x=data.train.images,\n",
    "          y=data.train.labels,\n",
    "          epochs=3,\n",
    "          batch_size=batch_size,\n",
    "          verbose=0)\n",
    "## Evaluation\n",
    "result = model.evaluate(x=data.test.images,\n",
    "                        y=data.test.labels,\n",
    "                        verbose=0)\n",
    "\n",
    "print(\"{0}: {1:.2%}\".format(model.metrics_names[1], result[1]),model.metrics_names[0],result[0])\n",
    "# Delete the Keras model with these hyper-parameters from memory. \n",
    "del model\n",
    "# Clear the Keras session, otherwise it will keep adding new\n",
    "# models to the same TensorFlow graph each time we create\n",
    "# a model with a different set of hyper-parameters.\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 48)        816       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 48)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 50)        21650     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 29)                71079     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                300       \n",
      "=================================================================\n",
      "Total params: 93,845\n",
      "Trainable params: 93,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 11.18% loss 2.30212396327\n",
      "Fold: 1\n",
      "acc: 11.05% loss 2.30125806548\n",
      "Fold: 2\n",
      "acc: 11.03% loss 2.30188119299\n",
      "Fold: 3\n",
      "acc: 11.40% loss 2.3010980398\n",
      "Fold: 4\n",
      "acc: 11.52% loss 2.30160554764\n",
      "0.112345454548\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 56)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 56)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 42)        58842     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 42)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2058)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 109)               224431    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1100      \n",
      "=================================================================\n",
      "Total params: 284,653\n",
      "Trainable params: 284,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 11.18% loss 2.30152043221\n",
      "Fold: 1\n",
      "acc: 11.05% loss 2.301500378\n",
      "Fold: 2\n",
      "acc: 11.03% loss 2.30199000497\n",
      "Fold: 3\n",
      "acc: 11.40% loss 2.30098575124\n",
      "Fold: 4\n",
      "acc: 11.52% loss 2.30148513291\n",
      "0.112345454548\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 24)        624       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 24)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 10)        970       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 490)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 45)                22095     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                460       \n",
      "=================================================================\n",
      "Total params: 24,149\n",
      "Trainable params: 24,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 97.92% loss 0.0726569117677\n",
      "Fold: 1\n",
      "acc: 97.54% loss 0.085363338699\n",
      "Fold: 2\n",
      "acc: 97.96% loss 0.0796885828196\n",
      "Fold: 3\n",
      "acc: 97.67% loss 0.0790999443882\n",
      "Fold: 4\n",
      "acc: 98.02% loss 0.066186193504\n",
      "0.97821818181\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 40)        80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 40)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 26)        1066      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 26)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1274)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                16575     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                140       \n",
      "=================================================================\n",
      "Total params: 17,861\n",
      "Trainable params: 17,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 90.46% loss 0.311518806956\n",
      "Fold: 1\n",
      "acc: 89.10% loss 0.362126386187\n",
      "Fold: 2\n",
      "acc: 89.01% loss 0.356475111376\n",
      "Fold: 3\n",
      "acc: 88.91% loss 0.345727324768\n",
      "Fold: 4\n",
      "acc: 86.95% loss 0.398472858646\n",
      "0.888872727273\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 9)         153       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 9)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 58)        8410      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 58)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2842)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 77)                218911    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                780       \n",
      "=================================================================\n",
      "Total params: 228,254\n",
      "Trainable params: 228,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 98.68% loss 0.0414806427399\n",
      "Fold: 1\n",
      "acc: 98.43% loss 0.0498028772955\n",
      "Fold: 2\n",
      "acc: 97.84% loss 0.0736812500317\n",
      "Fold: 3\n",
      "acc: 98.55% loss 0.0563369165214\n",
      "Fold: 4\n",
      "acc: 98.43% loss 0.0475788186845\n",
      "0.983836363636\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 27)        999       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 27)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 45)        10980     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 45)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2205)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 121)               266926    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1220      \n",
      "=================================================================\n",
      "Total params: 280,125\n",
      "Trainable params: 280,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 95.36% loss 0.154088128854\n",
      "Fold: 1\n",
      "acc: 93.59% loss 0.208823217804\n",
      "Fold: 2\n",
      "acc: 95.15% loss 0.168903373209\n",
      "Fold: 3\n",
      "acc: 96.25% loss 0.122129389255\n",
      "Fold: 4\n",
      "acc: 94.08% loss 0.186615956862\n",
      "0.948890909074\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 19)        95        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 19)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 71)        1420      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 71)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3479)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 34)                118320    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                350       \n",
      "=================================================================\n",
      "Total params: 120,185\n",
      "Trainable params: 120,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 97.76% loss 0.0757233048696\n",
      "Fold: 1\n",
      "acc: 97.55% loss 0.0846192478746\n",
      "Fold: 2\n",
      "acc: 97.68% loss 0.0805498808651\n",
      "Fold: 3\n",
      "acc: 97.54% loss 0.0863371517261\n",
      "Fold: 4\n",
      "acc: 97.44% loss 0.0826720770482\n",
      "0.975927272727\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         50        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 41)                64329     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                420       \n",
      "=================================================================\n",
      "Total params: 65,119\n",
      "Trainable params: 65,119\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 97.68% loss 0.0741737179079\n",
      "Fold: 1\n",
      "acc: 97.59% loss 0.0730239154674\n",
      "Fold: 2\n",
      "acc: 97.51% loss 0.0861724973338\n",
      "Fold: 3\n",
      "acc: 97.35% loss 0.084639812271\n",
      "Fold: 4\n",
      "acc: 96.76% loss 0.105153580888\n",
      "0.973799999974\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 34)        68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 34)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 40)        1400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 40)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1960)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 105)               205905    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1060      \n",
      "=================================================================\n",
      "Total params: 208,433\n",
      "Trainable params: 208,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 90.90% loss 0.285994997642\n",
      "Fold: 1\n",
      "acc: 90.19% loss 0.293865332788\n",
      "Fold: 2\n",
      "acc: 91.17% loss 0.269672391458\n",
      "Fold: 3\n",
      "acc: 91.36% loss 0.267680645314\n",
      "Fold: 4\n",
      "acc: 90.68% loss 0.287572084394\n",
      "0.908618181818\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 41)        205       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 41)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 27)        27702     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 27)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1323)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 156)               206544    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1570      \n",
      "=================================================================\n",
      "Total params: 236,021\n",
      "Trainable params: 236,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 11.18% loss 2.30210801159\n",
      "Fold: 1\n",
      "acc: 10.75% loss 2.30183563701\n",
      "Fold: 2\n",
      "acc: 11.03% loss 2.30240487029\n",
      "Fold: 3\n",
      "acc: 10.50% loss 2.3012198736\n",
      "Fold: 4\n",
      "acc: 11.52% loss 2.30204958985\n",
      "0.109945454547\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         50        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 53)        530       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 53)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2597)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 162)               420876    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1630      \n",
      "=================================================================\n",
      "Total params: 423,086\n",
      "Trainable params: 423,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 97.39% loss 0.0881993830752\n",
      "Fold: 1\n",
      "acc: 97.46% loss 0.0879443410925\n",
      "Fold: 2\n",
      "acc: 97.67% loss 0.0939434294684\n",
      "Fold: 3\n",
      "acc: 97.55% loss 0.0871087530729\n",
      "Fold: 4\n",
      "acc: 97.90% loss 0.0754409635964\n",
      "0.975945454545\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         10        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 93)        186       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 93)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4557)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4558      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                20        \n",
      "=================================================================\n",
      "Total params: 4,774\n",
      "Trainable params: 4,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 11.18% loss 2.30196179338\n",
      "Fold: 1\n",
      "acc: 32.08% loss 1.69571931007\n",
      "Fold: 2\n",
      "acc: 11.03% loss 2.30227035384\n",
      "Fold: 3\n",
      "acc: 30.74% loss 1.65914110435\n",
      "Fold: 4\n",
      "acc: 33.98% loss 1.62342900736\n",
      "0.238018181823\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         26        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 78)        1326      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 78)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3822)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 67)                256141    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                680       \n",
      "=================================================================\n",
      "Total params: 258,173\n",
      "Trainable params: 258,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 11.65% loss 2.3015217325\n",
      "Fold: 1\n",
      "acc: 11.05% loss 2.29955372464\n",
      "Fold: 2\n",
      "acc: 11.03% loss 2.30263995032\n",
      "Fold: 3\n",
      "acc: 11.40% loss 2.30081244798\n",
      "Fold: 4\n",
      "acc: 11.52% loss 2.30218113761\n",
      "0.113272727275\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 20)        100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 72)        1512      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 72)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3528)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 193)               681097    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1940      \n",
      "=================================================================\n",
      "Total params: 684,649\n",
      "Trainable params: 684,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 98.20% loss 0.0626742872061\n",
      "Fold: 1\n",
      "acc: 97.93% loss 0.06821073391\n",
      "Fold: 2\n",
      "acc: 97.72% loss 0.073950097654\n",
      "Fold: 3\n",
      "acc: 97.92% loss 0.0644054808349\n",
      "Fold: 4\n",
      "acc: 98.29% loss 0.0565490844158\n",
      "0.980109090892\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 53)        265       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 53)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 4)         7636      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 191)               37627     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1920      \n",
      "=================================================================\n",
      "Total params: 47,448\n",
      "Trainable params: 47,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 10.23% loss 2.30245973362\n",
      "Fold: 1\n",
      "acc: 11.05% loss 2.30166931291\n",
      "Fold: 2\n",
      "acc: 11.03% loss 2.30279115642\n",
      "Fold: 3\n",
      "acc: 9.57% loss 2.3017328949\n",
      "Fold: 4\n",
      "acc: 9.71% loss 2.30329555251\n",
      "0.103163636366\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         37        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 66)        660       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 66)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3234)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 198)               640530    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1990      \n",
      "=================================================================\n",
      "Total params: 643,217\n",
      "Trainable params: 643,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 97.83% loss 0.0766297503968\n",
      "Fold: 1\n",
      "acc: 97.45% loss 0.0823034918902\n",
      "Fold: 2\n",
      "acc: 97.33% loss 0.0908619271984\n",
      "Fold: 3\n",
      "acc: 97.05% loss 0.0966052335652\n",
      "Fold: 4\n",
      "acc: 97.60% loss 0.082628457614\n",
      "0.974527272693\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         17        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 98)        196       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 98)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4802)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4803      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                20        \n",
      "=================================================================\n",
      "Total params: 5,036\n",
      "Trainable params: 5,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 33.40% loss 1.64580394043\n",
      "Fold: 1\n",
      "acc: 35.51% loss 1.59863431315\n",
      "Fold: 2\n",
      "acc: 34.15% loss 1.59165242759\n",
      "Fold: 3\n",
      "acc: 32.91% loss 1.61312033489\n",
      "Fold: 4\n",
      "acc: 36.25% loss 1.58647110575\n",
      "0.344436363641\n",
      "linear\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         5         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 121)       3146      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 121)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5929)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 103)               610790    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1040      \n",
      "=================================================================\n",
      "Total params: 614,981\n",
      "Trainable params: 614,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 45.00% loss 2.23900014721\n",
      "Fold: 1\n",
      "acc: 48.76% loss 2.1753973862\n",
      "Fold: 2\n",
      "acc: 47.67% loss 2.1195796618\n",
      "Fold: 3\n",
      "acc: 54.60% loss 2.2308379879\n",
      "Fold: 4\n",
      "acc: 55.65% loss 2.10197945456\n",
      "0.503381818182\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         37        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 101)       1717      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 101)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4949)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 273)               1351350   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2740      \n",
      "=================================================================\n",
      "Total params: 1,355,844\n",
      "Trainable params: 1,355,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 97.65% loss 0.0882310079519\n",
      "Fold: 1\n",
      "acc: 97.35% loss 0.105790462375\n",
      "Fold: 2\n",
      "acc: 97.02% loss 0.104973332786\n",
      "Fold: 3\n",
      "acc: 95.54% loss 0.184650588404\n",
      "Fold: 4\n",
      "acc: 97.08% loss 0.105510081475\n",
      "0.969272727247\n",
      "sigmoid\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 20)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 1)         721       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 205)               10250     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2060      \n",
      "=================================================================\n",
      "Total params: 13,231\n",
      "Trainable params: 13,231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 11.18% loss 2.30265811331\n",
      "Fold: 1\n",
      "acc: 11.05% loss 2.30218349994\n",
      "Fold: 2\n",
      "acc: 11.03% loss 2.30189324119\n",
      "Fold: 3\n",
      "acc: 11.40% loss 2.30107450607\n",
      "Fold: 4\n",
      "acc: 11.52% loss 2.30181726768\n",
      "0.112345454548\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         10        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 79)        1343      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 79)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3871)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 174)               673728    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1750      \n",
      "=================================================================\n",
      "Total params: 676,831\n",
      "Trainable params: 676,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 97.81% loss 0.0712073235508\n",
      "Fold: 1\n",
      "acc: 97.80% loss 0.0715059733486\n",
      "Fold: 2\n",
      "acc: 98.38% loss 0.0533827129061\n",
      "Fold: 3\n",
      "acc: 97.84% loss 0.0724427821498\n",
      "Fold: 4\n",
      "acc: 98.06% loss 0.0630641014109\n",
      "0.979781818164\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         26        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 101)       202       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 101)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4949)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4950      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                20        \n",
      "=================================================================\n",
      "Total params: 5,198\n",
      "Trainable params: 5,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 35.15% loss 1.57565462355\n",
      "Fold: 1\n",
      "acc: 32.82% loss 1.58538568592\n",
      "Fold: 2\n",
      "acc: 31.94% loss 1.65956309258\n",
      "Fold: 3\n",
      "acc: 11.40% loss 2.30220538816\n",
      "Fold: 4\n",
      "acc: 32.84% loss 1.60916499372\n",
      "0.288290909091\n",
      "tanh\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         2         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 118)       3068      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 118)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5782)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 114)               659262    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1150      \n",
      "=================================================================\n",
      "Total params: 663,482\n",
      "Trainable params: 663,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 94.45% loss 0.189710190461\n",
      "Fold: 1\n",
      "acc: 97.58% loss 0.0813299426309\n",
      "Fold: 2\n",
      "acc: 95.30% loss 0.173355918317\n",
      "Fold: 3\n",
      "acc: 97.50% loss 0.086498493574\n",
      "Fold: 4\n",
      "acc: 95.25% loss 0.161685341971\n",
      "0.960145454528\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         82        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 109)       5450      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 109)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5341)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 182)               972244    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1830      \n",
      "=================================================================\n",
      "Total params: 979,606\n",
      "Trainable params: 979,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 97.56% loss 0.0821531186208\n",
      "Fold: 1\n",
      "acc: 96.54% loss 0.107295996858\n",
      "Fold: 2\n",
      "acc: 97.12% loss 0.10119981216\n",
      "Fold: 3\n",
      "acc: 97.43% loss 0.0896816440851\n",
      "Fold: 4\n",
      "acc: 97.05% loss 0.0942713013701\n",
      "0.971399999983\n",
      "relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 1)         17        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 208)               326352    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2090      \n",
      "=================================================================\n",
      "Total params: 329,003\n",
      "Trainable params: 329,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fold: 0\n",
      "acc: 98.06% loss 0.0646818504298\n",
      "Fold: 1\n",
      "acc: 98.18% loss 0.0594286933154\n",
      "Fold: 2\n",
      "acc: 97.76% loss 0.0760904058508\n",
      "Fold: 3\n",
      "acc: 97.93% loss 0.0664057067033\n",
      "Fold: 4\n",
      "acc: 98.08% loss 0.0600874736477\n",
      "0.980036363654\n",
      "{'activation': 0.20068359375, 'learning_rate': 0.00686066552734375, 'nodes_fcl_3': 77.33642578125, 'filterSize1': 4.00537109375, 'filterSize2': 4.05419921875, 'numFilter1': 9.15185546875, 'numFilter2': 58.06298828125}\n"
     ]
    }
   ],
   "source": [
    "## Create the neural network with these hyper-parameters\n",
    "def create_model (activation, learning_rate, nodes_fcl_3,\n",
    "                  filterSize1, filterSize2,\n",
    "                  numFilter1, numFilter2):\n",
    "    # Start construction of the Keras Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an input layer which is similar to a feed_dict in TensorFlow.\n",
    "    # Note that the input-shape must be a tuple containing the image-size.\n",
    "    model.add(InputLayer(input_shape=(img_size_flat,)))\n",
    "\n",
    "    # The input is a flattened array with 784 elements,\n",
    "    # but the convolutional layers expect images with shape (28, 28, 1)\n",
    "    model.add(Reshape(img_shape_full))\n",
    "\n",
    "    # First convolutional layer with ReLU-activation and max-pooling.\n",
    "    model.add(Conv2D(kernel_size=filterSize1, strides=1, filters=numFilter1, padding='same',\n",
    "                     activation=activation, name='layer_conv1'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "    # Second convolutional layer with ReLU-activation and max-pooling.\n",
    "    model.add(Conv2D(kernel_size=filterSize2, strides=1, filters=numFilter2, padding='same',\n",
    "                     activation=activation, name='layer_conv2'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "    # Flatten the 4-rank output of the convolutional layers\n",
    "    # to 2-rank that can be input to a fully-connected / dense layer.\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # First fully-connected / dense layer with ReLU-activation.\n",
    "    model.add(Dense(nodes_fcl_3, activation='relu'))\n",
    "\n",
    "    # Last fully-connected / dense layer with softmax-activation\n",
    "    # for use in classification.\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Use the Adam method for training the network.\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "    # In Keras we need to compile the model so it can be trained.\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "## Calculate the fitness value\n",
    "def calculate_fitness (activation, learning_rate, nodes_fcl_3,\n",
    "                       filterSize1, filterSize2,\n",
    "                       numFilter1, numFilter2):\n",
    "    # number of folds\n",
    "    k = 5 \n",
    "    # calculate the fold size\n",
    "    n_samples = len(data.train.images)\n",
    "    fold_size = n_samples // k\n",
    "    # Create list for saving the scores \n",
    "    scores = []\n",
    "    masks = []\n",
    "    for fold in range(k):\n",
    "        # Creation of the tensorFlow model with the PSO particle parameters\n",
    "        model = create_model(activation, learning_rate, nodes_fcl_3,\n",
    "                             filterSize1, filterSize2,\n",
    "                             numFilter1, numFilter2)\n",
    "        if fold == 0:\n",
    "            print(activation)\n",
    "            print(model.summary())\n",
    "        # generate a boolean mask for the test set in this fold\n",
    "        test_mask = np.zeros(n_samples, dtype=bool)\n",
    "        test_mask[fold * fold_size : (fold + 1) * fold_size] = True\n",
    "        # store the mask for visualization\n",
    "        masks.append(test_mask)\n",
    "        # create training and test sets using this mask\n",
    "        X_test, y_test = data.train.images[test_mask], data.train.labels[test_mask]\n",
    "        X_train, y_train = data.train.images[~test_mask], data.train.labels[~test_mask]\n",
    "        # fit the classifier\n",
    "        ## Training\n",
    "        model.fit(x=X_train,\n",
    "                  y=y_train,\n",
    "                  epochs=3,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=0)\n",
    "        ## Evaluation\n",
    "        result = model.evaluate(x=X_test,\n",
    "                                y=y_test,\n",
    "                                verbose=0)\n",
    "        # compute the score and record it\n",
    "        scores.append(result[1])\n",
    "       \n",
    "        print(\"Fold: \" + str(fold))        \n",
    "        print(\"{0}: {1:.2%}\".format(model.metrics_names[1], result[1]),model.metrics_names[0],result[0])\n",
    "        # Delete the Keras model with these hyper-parameters from memory. \n",
    "        del model\n",
    "        # Clear the Keras session, otherwise it will keep adding new\n",
    "        # models to the same TensorFlow graph each time we create\n",
    "        # a model with a different set of hyper-parameters.\n",
    "        K.clear_session()\n",
    "        session.close()\n",
    "    print(np.abs(np.mean(scores)))\n",
    "    return (np.abs(np.mean(scores)))\n",
    "\n",
    "start_time = time.time()\n",
    "f = create_objective_function()\n",
    "omega = 1.0/(2.0*np.log(2))\n",
    "phi = 0.5 + np.log(2)\n",
    "\n",
    "num_dense_layers = 1\n",
    "\n",
    "def create_objective_function():\n",
    "    def f(activation, learning_rate, nodes_fcl_3,\n",
    "          filterSize1, filterSize2,\n",
    "          numFilter1, numFilter2):\n",
    "\n",
    "        if (activation > 3):\n",
    "            activation = 3\n",
    "        if (nodes_fcl_3 < 1):\n",
    "            nodes_fcl_3 = 1\n",
    "        if (filterSize1 < 1):\n",
    "            filterSize1 = 1\n",
    "        if (filterSize2 < 1):\n",
    "            filterSize2 = 1\n",
    "        if (numFilter1 < 1):\n",
    "            numFilter1 = 1\n",
    "        if (numFilter2 < 1):\n",
    "            numFilter2 = 1  \n",
    "        if (learning_rate < min_learning_rate ):\n",
    "            learning_rate = min_learning_rate\n",
    "        fitness = 1.0/calculate_fitness(activation_cat[round(activation)],\n",
    "                                        learning_rate, int(nodes_fcl_3),\n",
    "                                        int(filterSize1), int(filterSize2),\n",
    "                                        int(numFilter1), int(numFilter2))\n",
    "        return fitness\n",
    "    return f\n",
    "\n",
    "pso = optunity.solvers.ParticleSwarm(num_particles=5,\n",
    "                                     num_generations=5,\n",
    "                                     max_speed=omega, \n",
    "                                     phi1=phi,phi2=phi,\n",
    "                                     activation=[0, 3], \n",
    "                                     learning_rate=[min_learning_rate, max_learning_rate], \n",
    "                                     nodes_fcl_3=[1, max_dense_nodes],\n",
    "                                     filterSize1 = [1, 6], \n",
    "                                     filterSize2 = [1, 6],\n",
    "                                     numFilter1  = [1, 64], \n",
    "                                     numFilter2  = [1, 64])\n",
    "pars,details = pso.minimize(f)\n",
    "print(pars)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "time_dif = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 8814.0912733078\n",
      "Activation function: relu\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 9)         153       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 9)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 58)        8410      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 58)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2842)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 77)                218911    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                780       \n",
      "=================================================================\n",
      "Total params: 228,254\n",
      "Trainable params: 228,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "acc: 98.62% loss 0.0435615411089\n"
     ]
    }
   ],
   "source": [
    "print(\"Time: \" + str(time_dif))\n",
    "\n",
    "\n",
    "model = create_model(activation_cat[round(pars['activation'])], pars['learning_rate'], \n",
    "                    int(pars['nodes_fcl_3']),\n",
    "                    int(pars['filterSize1']), int(pars['filterSize2']),\n",
    "                    int(pars['numFilter1']), int(pars['numFilter2']))\n",
    "    \n",
    "print(\"Activation function: \" + str(activation_cat[round(pars['activation'])]))\n",
    "print(model.summary())\n",
    "model.fit(x=data.train.images,\n",
    "          y=data.train.labels,\n",
    "          epochs=3,\n",
    "          batch_size=batch_size,\n",
    "          verbose=0)\n",
    "## Evaluation\n",
    "result = model.evaluate(x=data.test.images,\n",
    "                        y=data.test.labels,\n",
    "                        verbose=0)\n",
    "\n",
    "print(\"{0}: {1:.2%}\".format(model.metrics_names[1], result[1]),model.metrics_names[0],result[0])\n",
    "# Delete the Keras model with these hyper-parameters from memory. \n",
    "del model\n",
    "# Clear the Keras session, otherwise it will keep adding new\n",
    "# models to the same TensorFlow graph each time we create\n",
    "# a model with a different set of hyper-parameters.\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "| Topologiía | Accuracy | Lost | Parámetros |     Time    |\n",
    "|------------|----------|------|------------|-------------|\n",
    "|    CL      |  91.25%  |0.3025|   7,850    |      -      |\n",
    "|    RN 2    |  97.31%  |0.0855|  113,695   |   13 min    |\n",
    "|    RN 3    |  97.05%  |0.1064|  147,227   |   11 min    |\n",
    "|    RNC     |  98.62%  |0.0435|  228,254   | 2 hrs 45 min|\n",
    "\n",
    "- CL: Clasificador linal\n",
    "- RN 2: Red Neuronal con una capa oculta\n",
    "- RN 3: Red Neuronal con dos capas ocultas\n",
    "- RNC: Red Neuronal Convolucional"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
